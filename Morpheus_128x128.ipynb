{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "ac5a4cf0-d9d2-47b5-9633-b53f8d99a4d2",
     "kernelId": ""
    },
    "id": "SiTIpPjArIyr"
   },
   "source": [
    "# Morpheus 128x128 (ver. 1.0)\n",
    "\n",
    "***\n",
    "\n",
    "Powered by tegridy-tools TMIDIX Optimus Processors: https://github.com/asigalov61/tegridy-tools\n",
    "\n",
    "***\n",
    "\n",
    "Credit for GPT2-RGA code used in this colab goes out @ Sashmark97 https://github.com/Sashmark97/midigen and @ Damon Gwinn https://github.com/gwinndr/MusicTransformer-Pytorch\n",
    "\n",
    "***\n",
    "\n",
    "WARNING: This complete implementation is a functioning model of the Artificial Intelligence. Please excercise great humility, care, and respect. https://www.nscai.gov/\n",
    "\n",
    "***\n",
    "\n",
    "#### Project Los Angeles\n",
    "\n",
    "#### Tegridy Code 2022\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "fa0a611c-1803-42ae-bdf6-a49b5a4e781b",
     "kernelId": ""
    },
    "id": "gOd93yV0sGd2"
   },
   "source": [
    "# (Setup Environment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "gradient": {
     "editing": false,
     "id": "39411b40-9e39-416e-8fe4-d40f733e7956",
     "kernelId": ""
    },
    "id": "lw-4aqV3sKQG"
   },
   "outputs": [],
   "source": [
    "#@title nvidia-smi gpu check\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "gradient": {
     "editing": false,
     "id": "a1a45a91-d909-4fd4-b67a-5e16b971d179",
     "kernelId": ""
    },
    "id": "fX12Yquyuihc"
   },
   "outputs": [],
   "source": [
    "#@title Install all dependencies (run only once per session)\n",
    "\n",
    "!git clone https://github.com/asigalov61/tegridy-tools\n",
    "!pip install torch\n",
    "!pip install tqdm\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "gradient": {
     "editing": false,
     "id": "b8207b76-9514-4c07-95db-95a4742e52c5",
     "kernelId": ""
    },
    "id": "z7n9vnKmug1J"
   },
   "outputs": [],
   "source": [
    "#@title Import all needed modules\n",
    "\n",
    "print('Loading needed modules. Please wait...')\n",
    "import os\n",
    "import copy\n",
    "import tqdm as tqdm\n",
    "\n",
    "\n",
    "if not os.path.exists('/notebooks/Dataset'):\n",
    "    os.makedirs('/notebooks/Dataset')\n",
    "\n",
    "print('Loading TMIDIX module...')\n",
    "os.chdir('/notebooks/tegridy-tools/tegridy-tools')\n",
    "import TMIDIX\n",
    "\n",
    "os.chdir('/notebooks/tegridy-tools/tegridy-tools')\n",
    "from GPT2RGAX import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.chdir('/notebooks/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ObPxlEutsQBj"
   },
   "source": [
    "# (MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mdKFoeke9L7H"
   },
   "source": [
    "# (LOAD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "gradient": {
     "id": "c83edd89-9a36-430a-9fa7-3a967417c88e",
     "kernelId": ""
    },
    "id": "OaNkGcFo9UP_"
   },
   "outputs": [],
   "source": [
    "#@title Load/Reload the model\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "full_path_to_model_checkpoint = \"/notebooks/Morpheus-Trained-Model-2048.pth\" #@param {type:\"string\"}\n",
    "\n",
    "print('Loading the model...')\n",
    "config = GPTConfig(19200, \n",
    "                   2048,\n",
    "                   dim_feedforward=1024,\n",
    "                   n_layer=16, \n",
    "                   n_head=16, \n",
    "                   n_embd=1024,\n",
    "                   enable_rpr=True,\n",
    "                   er_len=2048)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = GPT(config)\n",
    "\n",
    "state_dict = torch.load(full_path_to_model_checkpoint, map_location=device)\n",
    "\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in state_dict.items():\n",
    "    name = k[7:] #remove 'module'\n",
    "    new_state_dict[name] = v\n",
    "\n",
    "model.load_state_dict(new_state_dict)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UX1_5y5Fu8AH"
   },
   "source": [
    "# (GENERATE MUSIC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MufDqdyBl4sa"
   },
   "source": [
    "## Custom MIDI option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = '/notebooks/tegridy-tools/tegridy-tools/seed2.mid'\n",
    "SONG = []\n",
    "#print('Loading MIDI file...')\n",
    "score = TMIDIX.midi2ms_score(open(f, 'rb').read())\n",
    "\n",
    "events_matrix = []\n",
    "\n",
    "itrack = 1\n",
    "stats = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "patches = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "patch_map = [[0, 1, 2, 3, 4, 5, 6, 7], # Piano \n",
    "             [24, 25, 26, 27, 28, 29, 30], # Guitar\n",
    "             [32, 33, 34, 35, 36, 37, 38, 39], # Bass\n",
    "             [40, 41], # Violin\n",
    "             [42, 43], # Cello\n",
    "             [46], # Harp\n",
    "             [56, 57, 58, 59, 60], # Trumpet\n",
    "             [71, 72], # Clarinet\n",
    "             [73, 74, 75], # Flute\n",
    "             [-1], # Fake Drums\n",
    "             [52, 53] # Choir\n",
    "            ]\n",
    "\n",
    "while itrack < len(score):\n",
    "    for event in score[itrack]:         \n",
    "        if event[0] == 'note' or event[0] == 'patch_change':\n",
    "            events_matrix.append(event)\n",
    "    itrack += 1\n",
    "\n",
    "events_matrix1 = []\n",
    "for event in events_matrix:\n",
    "        if event[0] == 'patch_change':\n",
    "            patches[event[2]] = event[3]\n",
    "\n",
    "        if event[0] == 'note':\n",
    "            event.extend([patches[event[3]]])\n",
    "            once = False\n",
    "\n",
    "            for p in patch_map:\n",
    "                if event[6] in p and event[3] != 9: # Except the drums\n",
    "                    event[3] = patch_map.index(p)\n",
    "                    once = True\n",
    "\n",
    "            if not once and event[3] != 9: # Except the drums\n",
    "                event[3] = 11 # All other instruments/patches channel\n",
    "\n",
    "            if event[3] < 11: # We won't write all other instruments for now...\n",
    "                events_matrix1.append(event)\n",
    "                stats[event[3]] += 1\n",
    "\n",
    "events_matrix1.sort()\n",
    "\n",
    "#=======================\n",
    "\n",
    "if len(events_matrix1) > 0:\n",
    "    events_matrix1.sort(key=lambda x: x[4], reverse=True)\n",
    "    events_matrix1.sort(key=lambda x: (x[1], x[3]))\n",
    "\n",
    "    cho = []\n",
    "    pe = events_matrix1[0]\n",
    "    melody_chords = []\n",
    "    for e in events_matrix1:\n",
    "\n",
    "        time = min(127, int(abs(e[1]-pe[1]) / 10))\n",
    "        dur = min(127, int(e[2] / 10))\n",
    "        cha = e[3]\n",
    "        ptc = e[4]\n",
    "        vel = e[5]\n",
    "\n",
    "        SONG.append([time, dur, ptc, cha, vel])\n",
    "\n",
    "        pe = e\n",
    "        \n",
    "        \n",
    "#====================================\n",
    "\n",
    "print('=' * 70)\n",
    "print('Converting to INTs...')\n",
    "\n",
    "times = []\n",
    "pitches = []\n",
    "\n",
    "itimes = []\n",
    "ipitches = []\n",
    "\n",
    "melody = []\n",
    "\n",
    "inputs = []\n",
    "\n",
    "for i in SONG:\n",
    "    \n",
    "    inputs.extend([i[0] + int(i[1] * 128)])\n",
    "\n",
    "    if i[0] != 0:\n",
    "        melody.extend([i[0] + int(i[1] * 128)])\n",
    "\n",
    "        if i[4] > 84:\n",
    "            melody.extend([(128*128) + 128 + (256 * i[3])+i[2]])\n",
    "        else:\n",
    "            melody.extend([(128*128) + (256 * i[3])+i[2]])\n",
    "\n",
    "    if i[3] < 10:\n",
    "      times.extend([i[0] + int(i[1] * 128)])\n",
    "\n",
    "      if i[4] > 84:\n",
    "          pitches.extend([(128*128) + 128 + (256 * i[3])+i[2]])\n",
    "      else:\n",
    "          pitches.extend([(128*128) + (256 * i[3])+i[2]])\n",
    "\n",
    "    if i[4] > 84:\n",
    "        inputs.extend([(128*128) + 128 + (256 * i[3])+i[2]])\n",
    "    else:\n",
    "        inputs.extend([(128*128) + (256 * i[3])+i[2]])\n",
    "\n",
    "    if i[3] < 10:\n",
    "          itimes.extend([i[0] + int(i[1] * 128)])\n",
    "\n",
    "          if i[4] > 84:\n",
    "              ipitches.extend([(128*128) + 128 + (256 * i[3])+i[2]])\n",
    "          else:\n",
    "              ipitches.extend([(128*128) + (256 * i[3])+i[2]])\n",
    "    pe = i\n",
    "\n",
    "print('=' * 70)\n",
    "print('Done!')\n",
    "print('Enjoy! :)')\n",
    "print('=' * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TOOBCgGQ2zoi"
   },
   "source": [
    "# Continuation Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "gradient": {
     "id": "97793d01-6a74-4e34-be95-ea337277b38d",
     "kernelId": ""
    },
    "id": "M_K93hWWv2Yx"
   },
   "outputs": [],
   "source": [
    "#@title Generate and download a MIDI file\n",
    "\n",
    "#@markdown NOTE: The first continuation sample may not be perfect, so generate several samples if you are not getting good results\n",
    "\n",
    "number_of_tokens_to_generate = 1024 #@param {type:\"slider\", min:512, max:1024, step:8}\n",
    "priming_type = \"Custom MIDI\" #@param [\"Intro\", \"Outro\", \"Custom MIDI\"]\n",
    "custom_MIDI_trim_type = \"From Start\" #@param [\"From Start\", \"From End\"]\n",
    "\n",
    "temperature = 0.8 #@param {type:\"slider\", min:0.1, max:1.3, step:0.1}\n",
    "\n",
    "show_stats = True #@param {type:\"boolean\"}\n",
    "\n",
    "number_of_instruments = 1\n",
    "\n",
    "#===================================================================\n",
    "\n",
    "tokens_range = (128*128) + (256 * number_of_instruments)\n",
    "\n",
    "fname = '/notebooks/Morpheus-Music-Composition'\n",
    "\n",
    "print('Morpheus Music Model Continuation Generator')\n",
    "\n",
    "output_signature = 'Morpheus'\n",
    "song_name = 'RGA Composition'\n",
    "out = []\n",
    "sequence = []\n",
    "if show_stats:\n",
    "  print('=' * 70)\n",
    "  print('Priming type:', priming_type)\n",
    "  print('Custom MIDI trim type:', custom_MIDI_trim_type)\n",
    "  print('Temperature:', temperature)\n",
    "  print('Tokens range:', tokens_range)\n",
    "\n",
    "print('=' * 70)\n",
    "if priming_type == 'Intro':\n",
    "    rand_seq = model.generate(torch.Tensor([(128*128)+(256 * 11)-1, \n",
    "                                            (128*128)+(256 * 11)-3]), \n",
    "                                            target_seq_length=number_of_tokens_to_generate,\n",
    "                                            temperature=temperature,\n",
    "                                            stop_token=tokens_range,\n",
    "                                            verbose=show_stats)\n",
    "    \n",
    "    out = rand_seq[0].cpu().numpy().tolist()\n",
    "\n",
    "if priming_type == 'Outro':\n",
    "    rand_seq = model.generate(torch.Tensor([(128*128)+(256 * 11)-2]), \n",
    "                              target_seq_length=number_of_tokens_to_generate,\n",
    "                              temperature=temperature,\n",
    "                              stop_token=tokens_range,\n",
    "                              verbose=show_stats)\n",
    "    \n",
    "    out = rand_seq[0].cpu().numpy().tolist()\n",
    "\n",
    "if priming_type == 'Custom MIDI' and inputs != []:\n",
    "    out = []\n",
    "\n",
    "    if custom_MIDI_trim_type == 'From Start':\n",
    "        sequence = inputs[:512]\n",
    "    else:\n",
    "        sequence = inputs[-512:]\n",
    "\n",
    "    rand_seq = model.generate(torch.Tensor(sequence), \n",
    "                              target_seq_length=number_of_tokens_to_generate, \n",
    "                              temperature=temperature,\n",
    "                              stop_token=tokens_range,\n",
    "                              verbose=show_stats)\n",
    "    \n",
    "    out = rand_seq[0].cpu().numpy().tolist()\n",
    "\n",
    "print('=' * 70)\n",
    "\n",
    "if len(out) != 0:\n",
    "    song = []\n",
    "    song = out\n",
    "    song_f = []\n",
    "    time = 0\n",
    "    dur = 1\n",
    "    vel = 0\n",
    "    pitch = 0\n",
    "    once = 0\n",
    "    duration = 0\n",
    "    for s in song:\n",
    "        if s >= 0 and s < 128 * 128:\n",
    "            time += (s % 128) * 10\n",
    "            dur = (s // 128) * 10\n",
    "\n",
    "        if s >= 128 * 128 and s < (128 * 128) + (256 * 11):\n",
    "            if (s // 128) % 2 != 0:\n",
    "                vel = 90\n",
    "                channel = ((s-128-(128 * 128)) // 256)\n",
    "            else:\n",
    "                vel = 60\n",
    "                channel = ((s-(128 * 128)) // 256)\n",
    "\n",
    "            pitch = s % 256\n",
    "\n",
    "            song_f.append(['note', abs(time), dur, channel, pitch, vel ])\n",
    "\n",
    "\n",
    "            if len(song_f) >= len(sequence) and once:\n",
    "                song_f.append(['text_event', abs(time) * 10, 'Continuation Start Here'])\n",
    "                once = False\n",
    "\n",
    "    detailed_stats = TMIDIX.Tegridy_SONG_to_MIDI_Converter(song_f,\n",
    "                                                          output_signature = 'Morpheus',  \n",
    "                                                          output_file_name = '/notebooks/Morpheus-Music-Composition', \n",
    "                                                          track_name='Project Los Angeles', \n",
    "                                                          number_of_ticks_per_quarter=500)\n",
    "\n",
    "    print('Done!')\n",
    "\n",
    "    if show_stats:\n",
    "      print('=' * 70)\n",
    "      print('Detailed MIDI stats:')\n",
    "      for key, value in detailed_stats.items():\n",
    "            print('=' * 70)\n",
    "            print(key, '|', value)\n",
    "\n",
    "    print('=' * 70)\n",
    "\n",
    "else:\n",
    "  print('Models output is empty! Check the code...')\n",
    "  print('Shutting down...')\n",
    "\n",
    "print('=' * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Melody Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Generate an accompaniment for the custom MIDI melody\n",
    "number_of_input_melody_notes = 128 #@param {type:\"slider\", min:16, max:256, step:16}\n",
    "number_of_instruments = 1\n",
    "temperature = 1\n",
    "\n",
    "print('=' * 70)\n",
    "\n",
    "\n",
    "print('Morpheus Music Model Melody Generator')\n",
    "print('=' * 70)\n",
    "\n",
    "song = []\n",
    "sng = copy.deepcopy(melody[:number_of_input_melody_notes])\n",
    "\n",
    "for i in tqdm(range(1024-2-number_of_input_melody_notes)):\n",
    "  \n",
    "    if len(sng)+2  >= 1024:\n",
    "        break\n",
    "\n",
    "    rand_seq = model.generate(torch.Tensor(sng), \n",
    "                              target_seq_length=len(sng) + 2,\n",
    "                              temperature=temperature,\n",
    "                              stop_token=(128*128)+(256 * number_of_instruments),\n",
    "                              verbose=False)\n",
    "\n",
    "    out = rand_seq[0].cpu().numpy().tolist()\n",
    "\n",
    "    if out[-2] % 128 != 0:  \n",
    "        sng.extend(out[-2:])\n",
    "\n",
    "print('=' * 70)\n",
    "print('Converting to MIDI...')\n",
    "\n",
    "if len(sng) != 0:\n",
    "    song = []\n",
    "    \n",
    "    song = sng\n",
    "   \n",
    "    song = sng[len(melody[:number_of_input_melody_notes * 2]):]\n",
    "    song_f = []\n",
    "    time = 0\n",
    "    dur = 1\n",
    "    vel = 0\n",
    "    pitch = 0\n",
    "    duration = 0\n",
    "    for s in song:\n",
    "        if s >= 0 and s < 128 * 128:\n",
    "            time += (s % 128) * 10\n",
    "            dur = (s // 128) * 10\n",
    "\n",
    "        if s >= 128 * 128 and s < (128 * 128) + (256 * 11):\n",
    "            if (s // 128) % 2 != 0:\n",
    "                vel = 90\n",
    "                channel = ((s-128-(128 * 128)) // 256)\n",
    "            else:\n",
    "                vel = 60\n",
    "                channel = ((s-(128 * 128)) // 256)\n",
    "\n",
    "            pitch = s % 256\n",
    "\n",
    "            song_f.append(['note', abs(time), dur, channel, pitch, vel ])\n",
    "      \n",
    "    detailed_stats = TMIDIX.Tegridy_SONG_to_MIDI_Converter(song_f,\n",
    "                                                          output_signature = 'Morpheus',  \n",
    "                                                          output_file_name = '/notebooks/Morpheus-Music-Composition', \n",
    "                                                          track_name='Project Los Angeles', \n",
    "                                                          number_of_ticks_per_quarter=500)\n",
    "\n",
    "    print('Done!')\n",
    "\n",
    "print('=' * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_RQi3EGweAO1"
   },
   "source": [
    "# Accompaniment Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rYEVUd-remHL"
   },
   "source": [
    "## Simple Accompaniment Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "j1WqkcfZeQX3"
   },
   "outputs": [],
   "source": [
    "#@title Generate an accompaniment for the custom MIDI melody\n",
    "number_of_input_melody_notes = 256 #@param {type:\"slider\", min:16, max:256, step:16}\n",
    "number_of_instruments = 10\n",
    "number_of_prime_notes = 0\n",
    "temperature = 0.8\n",
    "\n",
    "print('=' * 70)\n",
    "\n",
    "\n",
    "print('Morpheus Music Model Accompaniment Generator')\n",
    "print('=' * 70)\n",
    "\n",
    "song = []\n",
    "sng = []\n",
    "\n",
    "for i in range(number_of_prime_notes):\n",
    "    sng.append(times[i])\n",
    "    sng.append(pitches[i])\n",
    "    \n",
    "for i in tqdm(range(number_of_prime_notes, min(number_of_input_melody_notes, len(pitches)))):\n",
    "  \n",
    "    if len(sng) + 16 >= 1024:\n",
    "        break\n",
    "\n",
    "    rand_seq = model.generate(torch.Tensor(sng[-1006:] + [times[i], pitches[i]]), \n",
    "                              target_seq_length=len(sng[-1006:]) + 2 + 16, \n",
    "                              temperature=temperature,\n",
    "                              stop_token=(128*128)+(256 * number_of_instruments),\n",
    "                              verbose=False)\n",
    "\n",
    "    out = rand_seq[0].cpu().numpy().tolist()\n",
    "\n",
    "    outy = []\n",
    "\n",
    "    for o in out[len(sng[-1006:])+2:]:\n",
    "        if o < 128*128:\n",
    "            time = o % 128\n",
    "        \n",
    "        \n",
    "        \n",
    "        if time == 0:\n",
    "            outy.append(o)\n",
    "        else:\n",
    "            break\n",
    "    sng.extend([times[i], pitches[i]])\n",
    "    sng.extend(outy)\n",
    "    # print(len(outy))\n",
    "\n",
    "print('=' * 70)\n",
    "print('Converting to MIDI...')\n",
    "\n",
    "if len(sng) != 0:\n",
    "    song = []\n",
    "    song = sng\n",
    "    song_f = []\n",
    "    time = 0\n",
    "    dur = 1\n",
    "    vel = 0\n",
    "    pitch = 0\n",
    "    duration = 0\n",
    "    for s in song:\n",
    "        if s >= 0 and s < 128 * 128:\n",
    "            time += (s % 128) * 10\n",
    "            dur = (s // 128) * 10\n",
    "\n",
    "        if s >= 128 * 128 and s < (128 * 128) + (256 * 11):\n",
    "            if (s // 128) % 2 != 0:\n",
    "                vel = 90\n",
    "                channel = ((s-128-(128 * 128)) // 256)\n",
    "            else:\n",
    "                vel = 60\n",
    "                channel = ((s-(128 * 128)) // 256)\n",
    "\n",
    "            pitch = s % 256\n",
    "\n",
    "            song_f.append(['note', abs(time), dur, channel, pitch, vel ])\n",
    "            \n",
    "    detailed_stats = TMIDIX.Tegridy_SONG_to_MIDI_Converter(song_f,\n",
    "                                                          output_signature = 'Morpheus',  \n",
    "                                                          output_file_name = '/notebooks/Morpheus-Music-Composition', \n",
    "                                                          track_name='Project Los Angeles', \n",
    "                                                          number_of_ticks_per_quarter=500)\n",
    "\n",
    "    print('Done!')\n",
    "\n",
    "print('=' * 70) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pitches Inpainting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Generate an accompaniment for the custom MIDI melody\n",
    "number_of_input_melody_notes = 512 #@param {type:\"slider\", min:16, max:256, step:16}\n",
    "number_of_instruments = 1\n",
    "number_of_prime_notes = 32\n",
    "original_pitch_ratio = 2\n",
    "temperature = 0.8\n",
    "\n",
    "print('=' * 70)\n",
    "\n",
    "\n",
    "print('Morpheus Music Model Pitches Inpainting Generator')\n",
    "print('=' * 70)\n",
    "\n",
    "song = []\n",
    "sng = []\n",
    "tim = 0\n",
    "out = [0]\n",
    "\n",
    "for i in range(number_of_prime_notes):\n",
    "    sng.append(itimes[i])\n",
    "    sng.append(ipitches[i])\n",
    "\n",
    "for i in tqdm(range(number_of_prime_notes, min(number_of_input_melody_notes, len(ipitches))-1)):\n",
    "  \n",
    "    if len(sng) + 2 >= 1024:\n",
    "        break\n",
    "\n",
    "\n",
    "    rand_seq = model.generate(torch.Tensor(sng + [abs(itimes[i]) ]), \n",
    "                              target_seq_length=len(sng) + 2, \n",
    "                              stop_token=(128*128)+(256 * number_of_instruments),\n",
    "                              temperature=temperature\n",
    "                              verbose=False)\n",
    "\n",
    "    out = rand_seq[0].cpu().numpy().tolist()\n",
    "\n",
    "    \n",
    "    sng.extend([abs(itimes[i])])\n",
    "  \n",
    "    if i % original_pitch_ratio == 0:\n",
    "        sng.extend([pitches[i]])\n",
    "  \n",
    "    else:\n",
    "        sng.extend([out[-1]])\n",
    "\n",
    "print('=' * 70)\n",
    "print('Converting to MIDI...')\n",
    "\n",
    "if len(sng) != 0:\n",
    "    song = []\n",
    "    song = sng\n",
    "    song_f = []\n",
    "    time = 0\n",
    "    dur = 1\n",
    "    vel = 0\n",
    "    pitch = 0\n",
    "    duration = 0\n",
    "    for s in song:\n",
    "        if s >= 0 and s < 128 * 128:\n",
    "            time += (s % 128) * 10\n",
    "            dur = (s // 128) * 10\n",
    "\n",
    "        if s >= 128 * 128 and s < (128 * 128) + (256 * 11):\n",
    "            if (s // 128) % 2 != 0:\n",
    "                vel = 90\n",
    "                channel = ((s-128-(128 * 128)) // 256)\n",
    "            else:\n",
    "                vel = 60\n",
    "                channel = ((s-(128 * 128)) // 256)\n",
    "\n",
    "            pitch = s % 256\n",
    "\n",
    "            song_f.append(['note', abs(time), dur, channel, pitch, vel ])\n",
    "          \n",
    "      \n",
    "    detailed_stats = TMIDIX.Tegridy_SONG_to_MIDI_Converter(song_f,\n",
    "                                                          output_signature = 'Morpheus',  \n",
    "                                                          output_file_name = '/notebooks/Morpheus-Music-Composition', \n",
    "                                                          track_name='Project Los Angeles', \n",
    "                                                          number_of_ticks_per_quarter=500)\n",
    "\n",
    "else:\n",
    "  print('Models output is empty! Check the code...')\n",
    "  print('Shutting down...')\n",
    "\n",
    "print('=' * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YzCMd94Tu_gz"
   },
   "source": [
    "# Congrats! You did it! :)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "[MI] Continuano.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
