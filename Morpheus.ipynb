{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "ac5a4cf0-d9d2-47b5-9633-b53f8d99a4d2",
     "kernelId": ""
    },
    "id": "SiTIpPjArIyr"
   },
   "source": [
    "# Morpheus (ver. 1.0)\n",
    "\n",
    "***\n",
    "\n",
    "Powered by tegridy-tools TMIDIX Optimus Processors: https://github.com/asigalov61/tegridy-tools\n",
    "\n",
    "***\n",
    "\n",
    "Credit for GPT2-RGA code used in this colab goes out @ Sashmark97 https://github.com/Sashmark97/midigen and @ Damon Gwinn https://github.com/gwinndr/MusicTransformer-Pytorch\n",
    "\n",
    "***\n",
    "\n",
    "WARNING: This complete implementation is a functioning model of the Artificial Intelligence. Please excercise great humility, care, and respect. https://www.nscai.gov/\n",
    "\n",
    "***\n",
    "\n",
    "#### Project Los Angeles\n",
    "\n",
    "#### Tegridy Code 2021\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "fa0a611c-1803-42ae-bdf6-a49b5a4e781b",
     "kernelId": ""
    },
    "id": "gOd93yV0sGd2"
   },
   "source": [
    "# (Setup Environment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "gradient": {
     "editing": false,
     "id": "39411b40-9e39-416e-8fe4-d40f733e7956",
     "kernelId": ""
    },
    "id": "lw-4aqV3sKQG"
   },
   "outputs": [],
   "source": [
    "#@title nvidia-smi gpu check\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "gradient": {
     "editing": false,
     "id": "a1a45a91-d909-4fd4-b67a-5e16b971d179",
     "kernelId": ""
    },
    "id": "fX12Yquyuihc"
   },
   "outputs": [],
   "source": [
    "#@title Install all dependencies (run only once per session)\n",
    "\n",
    "!git clone https://github.com/asigalov61/tegridy-tools\n",
    "!pip install torch\n",
    "!pip install tqdm\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "gradient": {
     "editing": false,
     "id": "b8207b76-9514-4c07-95db-95a4742e52c5",
     "kernelId": ""
    },
    "id": "z7n9vnKmug1J"
   },
   "outputs": [],
   "source": [
    "#@title Import all needed modules\n",
    "\n",
    "print('Loading needed modules. Please wait...')\n",
    "import os\n",
    "from datetime import datetime\n",
    "import secrets\n",
    "import copy\n",
    "import tqdm as tqdm\n",
    "from tqdm import tqdm\n",
    "\n",
    "if not os.path.exists('/notebooks/Dataset'):\n",
    "    os.makedirs('/notebooks/Dataset')\n",
    "\n",
    "print('Loading TMIDIX module...')\n",
    "os.chdir('/notebooks/tegridy-tools/tegridy-tools')\n",
    "import TMIDIX\n",
    "\n",
    "os.chdir('/notebooks/tegridy-tools/tegridy-tools')\n",
    "from GPT2RGAX import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.chdir('/notebooks/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ObPxlEutsQBj"
   },
   "source": [
    "# (MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mdKFoeke9L7H"
   },
   "source": [
    "# (LOAD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "gradient": {
     "id": "c83edd89-9a36-430a-9fa7-3a967417c88e",
     "kernelId": ""
    },
    "id": "OaNkGcFo9UP_"
   },
   "outputs": [],
   "source": [
    "#@title Load/Reload the model\n",
    "full_path_to_model_checkpoint = \"/notebooks/Morpheus-Trained-Model.pth\" #@param {type:\"string\"}\n",
    "\n",
    "print('Loading the model...')\n",
    "config = GPTConfig(5640, \n",
    "                   max_seq,\n",
    "                   dim_feedforward=1024,\n",
    "                   n_layer=6, \n",
    "                   n_head=8, \n",
    "                   n_embd=1024,\n",
    "                   enable_rpr=True,\n",
    "                   er_len=max_seq)\n",
    "\n",
    "model = GPT(config).to(get_device())\n",
    "\n",
    "model.load_state_dict(torch.load(full_path_to_model_checkpoint))\n",
    "\n",
    "model.eval()\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UX1_5y5Fu8AH"
   },
   "source": [
    "# (GENERATE MUSIC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MufDqdyBl4sa"
   },
   "source": [
    "## Custom MIDI option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "gradient": {
     "id": "5f771604-39e7-431d-b1dd-86d7437b8872",
     "kernelId": ""
    },
    "id": "cOXRDAvOl4sa"
   },
   "outputs": [],
   "source": [
    "#@title Load your custom MIDI here\n",
    "full_path_tp_custom_MIDI = \"/notebooks/tegridy-tools/tegridy-tools/seed2.mid\" #@param {type:\"string\"}\n",
    "print('=' * 70)\n",
    "\n",
    "print('Loading custom MIDI...')\n",
    "\n",
    "print('File name:', full_path_tp_custom_MIDI)\n",
    "\n",
    "data = TMIDIX.Optimus_MIDI_TXT_Processor(full_path_tp_custom_MIDI, \n",
    "                                         dataset_MIDI_events_time_denominator=10, \n",
    "                                         perfect_timings=True, \n",
    "                                         musenet_encoding=True, \n",
    "                                         char_offset=0, \n",
    "                                         MIDI_channel=16, \n",
    "                                         MIDI_patch=range(0, 127)\n",
    "                                        )\n",
    "print('=' * 70)\n",
    "print('Converting to INTs...')\n",
    "\n",
    "times = []\n",
    "pitches = []\n",
    "\n",
    "itimes = []\n",
    "ipitches = []\n",
    "\n",
    "melody = []\n",
    "\n",
    "SONG = data[5]\n",
    "inputs = []\n",
    "\n",
    "for i in SONG:\n",
    "    if max(i) < 256 and min(i) >= 0 and i[2] < 10:\n",
    "\n",
    "        if i[0] != 0:\n",
    "            inputs.extend([i[0] + (int(i[1] / 25) * 256)])\n",
    "            \n",
    "            melody.extend([i[0] + (int(i[1] / 25) * 256)])\n",
    "            \n",
    "            if i[4] > 84:\n",
    "                melody.extend([(256 * 11) + 128 + (256 * i[2])+i[3]])\n",
    "            else:\n",
    "                melody.extend([(256 * 11) + (256 * i[2])+i[3]])\n",
    "\n",
    "            if i[2] < 10:\n",
    "              times.extend([i[0] + (int(i[1] / 25) * 256)])\n",
    "              \n",
    "              if i[4] > 84:\n",
    "                  pitches.extend([(256 * 11) + 128 + (256 * i[2])+i[3]])\n",
    "              else:\n",
    "                  pitches.extend([(256 * 11) + (256 * i[2])+i[3]])\n",
    "\n",
    "        if i[4] > 84:\n",
    "            inputs.extend([(256 * 11) + 128 + (256 * i[2])+i[3]])\n",
    "        else:\n",
    "            inputs.extend([(256 * 11) + (256 * i[2])+i[3]])\n",
    "        \n",
    "        if i[2] < 10:\n",
    "              itimes.extend([i[0] + (int(i[1] / 25) * 256)])\n",
    "              \n",
    "              if i[4] > 84:\n",
    "                  ipitches.extend([(256 * 11) + 128 + (256 * i[2])+i[3]])\n",
    "              else:\n",
    "                  ipitches.extend([(256 * 11) + (256 * i[2])+i[3]])\n",
    "        pe = i\n",
    "\n",
    "print('=' * 70)\n",
    "print('Done!')\n",
    "print('Enjoy! :)')\n",
    "print('=' * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TOOBCgGQ2zoi"
   },
   "source": [
    "# Continuation Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "gradient": {
     "id": "97793d01-6a74-4e34-be95-ea337277b38d",
     "kernelId": ""
    },
    "id": "M_K93hWWv2Yx"
   },
   "outputs": [],
   "source": [
    "#@title Generate and download a MIDI file\n",
    "\n",
    "#@markdown NOTE: The first continuation sample may not be perfect, so generate several samples if you are not getting good results\n",
    "\n",
    "number_of_tokens_to_generate = 1024 #@param {type:\"slider\", min:512, max:1024, step:8}\n",
    "priming_type = \"Custom MIDI\" #@param [\"Intro\", \"Outro\", \"Custom MIDI\"]\n",
    "custom_MIDI_trim_type = \"From Start\" #@param [\"From Start\", \"From End\"]\n",
    "\n",
    "temperature = 1 #@param {type:\"slider\", min:0.1, max:1.3, step:0.1}\n",
    "\n",
    "show_stats = True #@param {type:\"boolean\"}\n",
    "\n",
    "number_of_instruments = 1\n",
    "\n",
    "#===================================================================\n",
    "\n",
    "tokens_range = (256 * 11) + (256 * number_of_instruments)\n",
    "\n",
    "fname = '/notebooks/Morpheus-Music-Composition'\n",
    "\n",
    "print('Morpheus Music Model Continuation Generator')\n",
    "\n",
    "output_signature = 'Morpheus'\n",
    "song_name = 'RGA Composition'\n",
    "out = []\n",
    "if show_stats:\n",
    "  print('=' * 70)\n",
    "  print('Priming type:', priming_type)\n",
    "  print('Custom MIDI trim type:', custom_MIDI_trim_type)\n",
    "  print('Temperature:', temperature)\n",
    "  print('Tokens range:', tokens_range)\n",
    "\n",
    "print('=' * 70)\n",
    "if priming_type == 'Intro':\n",
    "    rand_seq = model.generate(torch.Tensor([(256 * 11)+(256 * 11)-1, \n",
    "                                            (256 * 11)+(256 * 11)-3]), \n",
    "                                            target_seq_length=number_of_tokens_to_generate,\n",
    "                                            temperature=temperature,\n",
    "                                            stop_token=tokens_range,\n",
    "                                            verbose=show_stats)\n",
    "    \n",
    "    out = rand_seq[0].cpu().numpy().tolist()\n",
    "\n",
    "if priming_type == 'Outro':\n",
    "    rand_seq = model.generate(torch.Tensor([(256 * 11)+(256 * 11)-2]), \n",
    "                              target_seq_length=number_of_tokens_to_generate,\n",
    "                              temperature=temperature,\n",
    "                              stop_token=tokens_range,\n",
    "                              verbose=show_stats)\n",
    "    \n",
    "    out = rand_seq[0].cpu().numpy().tolist()\n",
    "\n",
    "if priming_type == 'Custom MIDI' and inputs != []:\n",
    "    out = []\n",
    "\n",
    "    if custom_MIDI_trim_type == 'From Start':\n",
    "      sequence = inputs[:512]\n",
    "    else:\n",
    "      sequence = inputs[-512:]\n",
    "\n",
    "    rand_seq = model.generate(torch.Tensor(sequence), \n",
    "                              target_seq_length=number_of_tokens_to_generate, \n",
    "                              temperature=temperature,\n",
    "                              stop_token=tokens_range,\n",
    "                              verbose=show_stats)\n",
    "    \n",
    "    out = rand_seq[0].cpu().numpy().tolist()\n",
    "\n",
    "print('=' * 70)\n",
    "\n",
    "if len(out) != 0:\n",
    "    song = []\n",
    "    song = out\n",
    "    song_f = []\n",
    "    time = 0\n",
    "    dur = 0\n",
    "    vel = 0\n",
    "    pitch = 0\n",
    "    duration = 0\n",
    "    once = True\n",
    "    for s in song:\n",
    "        if s >= 0 and s <= 256 * 11:\n",
    "            time += s % 256\n",
    "            dur = ((s // 256) + 1) * 250\n",
    "\n",
    "        if s >= 256 * 11 and s < (256 * 21):\n",
    "            if (s // 128) % 2 != 0:\n",
    "                vel = 80 + (s % 256) % 24\n",
    "                channel = ((s-128-(256*11)) // 256)\n",
    "            else:\n",
    "                vel = 64 + (s % 256) % 24\n",
    "                channel = ((s-(256*11)) // 256)\n",
    "\n",
    "            pitch = s % 256\n",
    "\n",
    "            song_f.append(['note', (abs(time))*10, dur, channel, pitch, vel ])\n",
    "\n",
    "            if song.index(s) >= len(sequence) and once:\n",
    "                song_f.append(['text_event', abs(time) * 10, 'Continuation Start Here'])\n",
    "                once = False\n",
    "\n",
    "    detailed_stats = TMIDIX.Tegridy_SONG_to_MIDI_Converter(song_f,\n",
    "                                                          output_signature = 'Morpheus',  \n",
    "                                                          output_file_name = '/notebooks/Morpheus-Music-Composition', \n",
    "                                                          track_name='Project Los Angeles', \n",
    "                                                          number_of_ticks_per_quarter=500)\n",
    "\n",
    "    print('Done!')\n",
    "\n",
    "    if show_stats:\n",
    "      print('=' * 70)\n",
    "      print('Detailed MIDI stats:')\n",
    "      for key, value in detailed_stats.items():\n",
    "            print('=' * 70)\n",
    "            print(key, '|', value)\n",
    "\n",
    "    print('=' * 70)\n",
    "\n",
    "else:\n",
    "  print('Models output is empty! Check the code...')\n",
    "  print('Shutting down...')\n",
    "\n",
    "print('=' * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Melody Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Generate an accompaniment for the custom MIDI melody\n",
    "number_of_input_melody_notes = 128 #@param {type:\"slider\", min:16, max:256, step:16}\n",
    "number_of_instruments = 1\n",
    "output_original_and_generated_melodies = False\n",
    "print('=' * 70)\n",
    "\n",
    "\n",
    "print('Morpheus Music Model Melody Generator')\n",
    "print('=' * 70)\n",
    "\n",
    "song = []\n",
    "sng = melody[:number_of_input_melody_notes * 2]\n",
    "\n",
    "for i in tqdm(range(number_of_input_melody_notes)):\n",
    "  \n",
    "  if len(sng)+2  >= 1024:\n",
    "    break\n",
    "  \n",
    "\n",
    "  rand_seq = model.generate(torch.Tensor(sng), \n",
    "                              target_seq_length=len(sng) + 2,\n",
    "                              temperature=1,\n",
    "                              stop_token=(256*11)+(256 * number_of_instruments),\n",
    "                              verbose=False)\n",
    "\n",
    "  out = rand_seq[0].cpu().numpy().tolist()\n",
    "\n",
    "  if out[-2] < 256 * 11 and out[-1] > 256 * 11:\n",
    "      sng.extend(out[-2:])\n",
    "\n",
    "print('=' * 70)\n",
    "print('Converting to MIDI...')\n",
    "\n",
    "if len(sng) != 0:\n",
    "    song = []\n",
    "    if output_original_and_generated_melodies:\n",
    "        song = sng\n",
    "    else:\n",
    "        song = sng[len(melody[:number_of_input_melody_notes * 2]):]\n",
    "    song_f = []\n",
    "    time = 0\n",
    "    dur = 0\n",
    "    vel = 0\n",
    "    pitch = 0\n",
    "    duration = 0\n",
    "    once = True\n",
    "    for s in song:\n",
    "        if s >= 0 and s <= 256 * 11:\n",
    "            time += s % 256\n",
    "            dur = ((s // 256) + 1) * 250\n",
    "\n",
    "        if s >= 256 * 11 and s < (256 * 21):\n",
    "            if (s // 128) % 2 != 0:\n",
    "                vel = 80 + (s % 256) % 24\n",
    "                channel = ((s-128-(256*11)) // 256)\n",
    "            else:\n",
    "                vel = 64 + (s % 256) % 24\n",
    "                channel = ((s-(256*11)) // 256)\n",
    "\n",
    "            pitch = s % 256\n",
    "\n",
    "            song_f.append(['note', (abs(time))*10, dur, channel, pitch, vel ])\n",
    "      \n",
    "    detailed_stats = TMIDIX.Tegridy_SONG_to_MIDI_Converter(song_f,\n",
    "                                                          output_signature = 'Morpheus',  \n",
    "                                                          output_file_name = '/notebooks/Morpheus-Music-Composition', \n",
    "                                                          track_name='Project Los Angeles', \n",
    "                                                          number_of_ticks_per_quarter=500)\n",
    "\n",
    "    print('Done!')\n",
    "\n",
    "print('=' * 70)\n",
    "\n",
    "times = []\n",
    "pitches = []\n",
    "\n",
    "if output_original_and_generated_melodies:\n",
    "    for i in range(0, len(sng)-2, 2):\n",
    "       times.append(sng[i])\n",
    "       pitches.append(sng[i+1])\n",
    "\n",
    "else:\n",
    "    for i in range(len(melody[:number_of_input_melody_notes * 2]), len(sng)-2, 2):\n",
    "       times.append(sng[i])\n",
    "       pitches.append(sng[i+1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_RQi3EGweAO1"
   },
   "source": [
    "# Accompaniment Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rYEVUd-remHL"
   },
   "source": [
    "## Simple Accompaniment Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "j1WqkcfZeQX3"
   },
   "outputs": [],
   "source": [
    "#@title Generate an accompaniment for the custom MIDI melody\n",
    "number_of_input_melody_notes = 256 #@param {type:\"slider\", min:16, max:256, step:16}\n",
    "number_of_instruments = 10\n",
    "number_of_prime_notes = 0\n",
    "\n",
    "print('=' * 70)\n",
    "\n",
    "\n",
    "print('Morpheus Music Model Accompaniment Generator')\n",
    "print('=' * 70)\n",
    "\n",
    "song = []\n",
    "sng = []\n",
    "\n",
    "for i in range(number_of_prime_notes):\n",
    "    sng.append(times[i])\n",
    "    sng.append(pitches[i])\n",
    "    \n",
    "for i in tqdm(range(number_of_prime_notes, min(number_of_input_melody_notes, len(pitches)))):\n",
    "  \n",
    "  #if len(sng + [times[i], pitches[i]]) + 16 >= 1024:\n",
    "    #break\n",
    "  \n",
    "  rand_seq = model.generate(torch.Tensor(sng[-1006:] + [times[i], pitches[i]]), \n",
    "                              target_seq_length=len(sng[-1006:]) + 2 + 16, \n",
    "                              temperature=1,\n",
    "                              stop_token=(256*11)+(256 * number_of_instruments),\n",
    "                              verbose=False)\n",
    "    \n",
    "  out = rand_seq[0].cpu().numpy().tolist()\n",
    "\n",
    "  outy = []\n",
    "  \n",
    "  for o in out[len(sng[-1006:])+2:]:\n",
    "    if o >=256 * 11:\n",
    "      outy.append(o)\n",
    "    else:\n",
    "      break\n",
    "  sng.extend([times[i], pitches[i]])\n",
    "  sng.extend(outy)\n",
    "  # print(len(outy))\n",
    "\n",
    "print('=' * 70)\n",
    "print('Converting to MIDI...')\n",
    "\n",
    "if len(sng) != 0:\n",
    "    song = []\n",
    "    song = sng\n",
    "    song_f = []\n",
    "    time = 0\n",
    "    dur = 0\n",
    "    vel = 0\n",
    "    pitch = 0\n",
    "    duration = 0\n",
    "    once = True\n",
    "    for s in song:\n",
    "        if s >= 0 and s <= 256 * 11:\n",
    "            time += s % 256\n",
    "            dur = ((s // 256) + 1) * 250\n",
    "\n",
    "        if s >= 256 * 11 and s < (256 * 21):\n",
    "            if (s // 128) % 2 != 0:\n",
    "                vel = 80 + (s % 256) % 24\n",
    "                channel = ((s-128-(256*11)) // 256)\n",
    "            else:\n",
    "                vel = 64 + (s % 256) % 24\n",
    "                channel = ((s-(256*11)) // 256)\n",
    "\n",
    "            pitch = s % 256\n",
    "\n",
    "            song_f.append(['note', (abs(time))*10, dur, channel, pitch, vel ])\n",
    "      \n",
    "    detailed_stats = TMIDIX.Tegridy_SONG_to_MIDI_Converter(song_f,\n",
    "                                                          output_signature = 'Morpheus',  \n",
    "                                                          output_file_name = '/notebooks/Morpheus-Music-Composition', \n",
    "                                                          track_name='Project Los Angeles', \n",
    "                                                          number_of_ticks_per_quarter=500)\n",
    "\n",
    "    print('Done!')\n",
    "\n",
    "print('=' * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TgdoWM7lepkL"
   },
   "source": [
    "## Advanced Accompaniment Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "noW4aO8dOrmV"
   },
   "outputs": [],
   "source": [
    "#@title Generate an accompaniment for the custom MIDI melody\n",
    "number_of_input_melody_notes = 256 #@param {type:\"slider\", min:16, max:256, step:16}\n",
    "number_of_instruments = 10\n",
    "minimum_beat_delta_time = 12\n",
    "number_of_prime_notes = 0\n",
    "\n",
    "print('=' * 70)\n",
    "\n",
    "\n",
    "print('Morpheus Music Model Advanced Accompaniment Generator')\n",
    "print('=' * 70)\n",
    "\n",
    "song = []\n",
    "sng = []\n",
    "tim = 0\n",
    "\n",
    "for i in range(number_of_prime_notes):\n",
    "    sng.append(times[i])\n",
    "    sng.append(pitches[i])\n",
    "\n",
    "for i in tqdm(range(number_of_prime_notes, min(number_of_input_melody_notes, len(pitches))-1)):\n",
    "  \n",
    "  #if len(sng) + 2 + 16 >= 1024:\n",
    "    #break\n",
    "  \n",
    "  rand_seq = model.generate(torch.Tensor(sng[-1006:] + [abs(times[i]-tim), pitches[i]]), \n",
    "                              target_seq_length=len(sng[-1006:]) + 2 + 16, \n",
    "                              stop_token=(256*11)+(256 * number_of_instruments),\n",
    "                              verbose=False)\n",
    "    \n",
    "  out = rand_seq[0].cpu().numpy().tolist()\n",
    "    \n",
    "  sng.extend([abs(times[i]-tim), pitches[i]])\n",
    "\n",
    "  outy = []\n",
    "  tim = 0\n",
    "\n",
    "  for o in out[len(sng[-1006:]):]:\n",
    "    if o >=(256*11):\n",
    "      outy.append(o)\n",
    "\n",
    "    else:\n",
    "      if ((times[i+1] % 256) -tim)  > o % 256 and o % 256 > minimum_beat_delta_time * 2:\n",
    "         outy.append(o)\n",
    "         tim += o % 256 \n",
    "      else:\n",
    "         break\n",
    "\n",
    "  sng.extend(outy)\n",
    "\n",
    "print('=' * 70)\n",
    "print('Converting to MIDI...')\n",
    "\n",
    "if len(sng) != 0:\n",
    "    song = []\n",
    "    song = sng\n",
    "    song_f = []\n",
    "    time = 0\n",
    "    dur = 0\n",
    "    vel = 0\n",
    "    pitch = 0\n",
    "    duration = 0\n",
    "    once = True\n",
    "    for s in song:\n",
    "        if s >= 0 and s <= 256 * 11:\n",
    "            time += s % 256\n",
    "            dur = ((s // 256) + 1) * 250\n",
    "\n",
    "        if s >= 256 * 11 and s < (256 * 21):\n",
    "            if (s // 128) % 2 != 0:\n",
    "                vel = 80 + (s % 256) % 24\n",
    "                channel = ((s-128-(256*11)) // 256)\n",
    "            \n",
    "            else:\n",
    "                vel = 64 + (s % 256) % 24\n",
    "                channel = ((s-(256*11)) // 256)\n",
    "\n",
    "            pitch = s % 256\n",
    "\n",
    "            song_f.append(['note', (abs(time))*10, dur, channel, pitch, vel ])\n",
    "          \n",
    "      \n",
    "    detailed_stats = TMIDIX.Tegridy_SONG_to_MIDI_Converter(song_f,\n",
    "                                                          output_signature = 'Morpheus',  \n",
    "                                                          output_file_name = '/notebooks/Morpheus-Music-Composition', \n",
    "                                                          track_name='Project Los Angeles', \n",
    "                                                          number_of_ticks_per_quarter=500)\n",
    "\n",
    "else:\n",
    "  print('Models output is empty! Check the code...')\n",
    "  print('Shutting down...')\n",
    "\n",
    "print('=' * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pitches Inpainting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Generate an accompaniment for the custom MIDI melody\n",
    "number_of_input_melody_notes = 400 #@param {type:\"slider\", min:16, max:256, step:16}\n",
    "number_of_instruments = 3\n",
    "number_of_prime_notes = 64\n",
    "original_pitch_ratio = 4\n",
    "\n",
    "print('=' * 70)\n",
    "\n",
    "\n",
    "print('Morpheus Music Model Pitches Inpainting Generator')\n",
    "print('=' * 70)\n",
    "\n",
    "song = []\n",
    "sng = []\n",
    "tim = 0\n",
    "out = [0]\n",
    "\n",
    "for i in range(number_of_prime_notes):\n",
    "    sng.append(itimes[i])\n",
    "    sng.append(ipitches[i])\n",
    "\n",
    "for i in tqdm(range(number_of_prime_notes, min(number_of_input_melody_notes, len(ipitches))-1)):\n",
    "  \n",
    "  if len(sng) + 2 >= 1024:\n",
    "    break\n",
    "  \n",
    "  for j in range(100):\n",
    "\n",
    "      rand_seq = model.generate(torch.Tensor(sng + [abs(itimes[i]) ]), \n",
    "                                  target_seq_length=len(sng) + 2, \n",
    "                                  stop_token=(256*11)+(256 * number_of_instruments),\n",
    "                                  verbose=False)\n",
    "\n",
    "      out = rand_seq[0].cpu().numpy().tolist()\n",
    "        \n",
    "      if out[-1] > 256 * 11:\n",
    "        break\n",
    "    \n",
    "  sng.extend([abs(itimes[i])])\n",
    "  \n",
    "  if i % original_pitch_ratio == 0:\n",
    "    sng.extend([pitches[i]])\n",
    "  \n",
    "  else:\n",
    "    sng.extend([out[-1]])\n",
    "\n",
    "print('=' * 70)\n",
    "print('Converting to MIDI...')\n",
    "\n",
    "if len(sng) != 0:\n",
    "    song = []\n",
    "    song = sng\n",
    "    song_f = []\n",
    "    time = 0\n",
    "    dur = 0\n",
    "    vel = 0\n",
    "    pitch = 0\n",
    "    duration = 0\n",
    "    once = True\n",
    "    for s in song:\n",
    "        if s >= 0 and s <= 256 * 11:\n",
    "            time += s % 256\n",
    "            dur = ((s // 256) + 1) * 250\n",
    "\n",
    "        if s >= 256 * 11 and s < (256 * 21):\n",
    "            if (s // 128) % 2 != 0:\n",
    "                vel = 80 + (s % 256) % 24\n",
    "                channel = ((s-128-(256*11)) // 256)\n",
    "            \n",
    "            else:\n",
    "                vel = 64 + (s % 256) % 24\n",
    "                channel = ((s-(256*11)) // 256)\n",
    "\n",
    "            pitch = s % 256\n",
    "\n",
    "            song_f.append(['note', (abs(time))*10, dur, channel, pitch, vel ])\n",
    "          \n",
    "      \n",
    "    detailed_stats = TMIDIX.Tegridy_SONG_to_MIDI_Converter(song_f,\n",
    "                                                          output_signature = 'Morpheus',  \n",
    "                                                          output_file_name = '/notebooks/Morpheus-Music-Composition', \n",
    "                                                          track_name='Project Los Angeles', \n",
    "                                                          number_of_ticks_per_quarter=500)\n",
    "\n",
    "else:\n",
    "  print('Models output is empty! Check the code...')\n",
    "  print('Shutting down...')\n",
    "\n",
    "print('=' * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YzCMd94Tu_gz"
   },
   "source": [
    "# Congrats! You did it! :)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "[MI] Continuano.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
