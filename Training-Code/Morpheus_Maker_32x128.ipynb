{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "ac5a4cf0-d9d2-47b5-9633-b53f8d99a4d2",
     "kernelId": ""
    },
    "id": "SiTIpPjArIyr"
   },
   "source": [
    "# Morpheus Maker (ver. 2.0)\n",
    "\n",
    "***\n",
    "\n",
    "Powered by tegridy-tools TMIDIX Optimus Processors: https://github.com/asigalov61/tegridy-tools\n",
    "\n",
    "***\n",
    "\n",
    "Credit for GPT2-RGA code used in this colab goes out @ Sashmark97 https://github.com/Sashmark97/midigen and @ Damon Gwinn https://github.com/gwinndr/MusicTransformer-Pytorch\n",
    "\n",
    "***\n",
    "\n",
    "WARNING: This complete implementation is a functioning model of the Artificial Intelligence. Please excercise great humility, care, and respect. https://www.nscai.gov/\n",
    "\n",
    "***\n",
    "\n",
    "#### Project Los Angeles\n",
    "\n",
    "#### Tegridy Code 2022\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "fa0a611c-1803-42ae-bdf6-a49b5a4e781b",
     "kernelId": ""
    },
    "id": "gOd93yV0sGd2"
   },
   "source": [
    "# (Setup Environment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "gradient": {
     "editing": false,
     "id": "39411b40-9e39-416e-8fe4-d40f733e7956",
     "kernelId": ""
    },
    "id": "lw-4aqV3sKQG"
   },
   "outputs": [],
   "source": [
    "#@title nvidia-smi gpu check\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "gradient": {
     "editing": false,
     "id": "a1a45a91-d909-4fd4-b67a-5e16b971d179",
     "kernelId": ""
    },
    "id": "fX12Yquyuihc"
   },
   "outputs": [],
   "source": [
    "#@title Install all dependencies (run only once per session)\n",
    "\n",
    "!git clone https://github.com/asigalov61/tegridy-tools\n",
    "!pip install torch\n",
    "!pip install tqdm\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "gradient": {
     "editing": false,
     "id": "b8207b76-9514-4c07-95db-95a4742e52c5",
     "kernelId": ""
    },
    "id": "z7n9vnKmug1J"
   },
   "outputs": [],
   "source": [
    "#@title Import all needed modules\n",
    "\n",
    "print('Loading needed modules. Please wait...')\n",
    "import os\n",
    "from datetime import datetime\n",
    "import secrets\n",
    "import copy\n",
    "import tqdm as tqdm\n",
    "from tqdm import tqdm\n",
    "\n",
    "if not os.path.exists('/notebooks/Dataset'):\n",
    "    os.makedirs('/notebooks/Dataset')\n",
    "\n",
    "print('Loading TMIDIX module...')\n",
    "os.chdir('/notebooks/tegridy-tools/tegridy-tools')\n",
    "import TMIDIX\n",
    "\n",
    "os.chdir('/notebooks/tegridy-tools/tegridy-tools')\n",
    "from GPT2RGAX import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.chdir('/notebooks/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "20b8698a-0b4e-4fdb-ae49-24d063782e77",
     "kernelId": ""
    },
    "id": "ObPxlEutsQBj"
   },
   "source": [
    "# (FROM SCRATCH) Download and process MIDI dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "gradient": {
     "editing": false,
     "id": "ffbb7a2a-d91a-477f-ac89-56d77d6cdf42",
     "kernelId": ""
    },
    "id": "snIZ3xKPsPgB"
   },
   "outputs": [],
   "source": [
    "#@title Download original LAKH/clean_midi MIDI subset (Recommended)\n",
    "\n",
    "#@markdown Works best stand-alone/as-is for the optimal results\n",
    "%cd /notebooks/\n",
    "\n",
    "!wget 'http://hog.ee.columbia.edu/craffel/lmd/clean_midi.tar.gz'\n",
    "!tar -xvf 'clean_midi.tar.gz'\n",
    "!rm 'clean_midi.tar.gz'\n",
    "\n",
    "%cd /notebooks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "gradient": {
     "id": "ed07b44f-07fe-45fb-a64f-adba8df1bdcb",
     "kernelId": ""
    },
    "id": "on7sgKEP3Yc8"
   },
   "outputs": [],
   "source": [
    "#@title Process MIDIs to special MIDI dataset with TMIDIX MIDI Processor\n",
    "\n",
    "#@title Process MIDIs\n",
    "\n",
    "sorted_or_random_file_loading_order = False # Sorted order is NOT recommended\n",
    "dataset_ratio = 0.02 # Change this if you need more data\n",
    "\n",
    "\n",
    "print('TMIDIX MIDI Processor')\n",
    "print('Starting up...')\n",
    "###########\n",
    "\n",
    "files_count = 0\n",
    "\n",
    "gfiles = []\n",
    "\n",
    "melody_chords_f = []\n",
    "\n",
    "###########\n",
    "\n",
    "print('Loading MIDI files...')\n",
    "print('This may take a while on a large dataset in particular.')\n",
    "\n",
    "dataset_addr = \"./clean_midi/\"\n",
    "# os.chdir(dataset_addr)\n",
    "filez = list()\n",
    "for (dirpath, dirnames, filenames) in os.walk(dataset_addr):\n",
    "    filez += [os.path.join(dirpath, file) for file in filenames]\n",
    "print('=' * 70)\n",
    "\n",
    "if filez == []:\n",
    "    print('Could not find any MIDI files. Please check Dataset dir...')\n",
    "    print('=' * 70)\n",
    "\n",
    "if sorted_or_random_file_loading_order:\n",
    "    print('Sorting files...')\n",
    "    filez.sort()\n",
    "    print('Done!')\n",
    "    print('=' * 70)\n",
    "else:\n",
    "    print('Randomizing file list...')\n",
    "    random.shuffle(filez)\n",
    "\n",
    "    \n",
    "stats = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "print('Processing MIDI files. Please wait...')\n",
    "for f in tqdm(filez[:int(len(filez) * dataset_ratio)]):\n",
    "    try:\n",
    "        fn = os.path.basename(f)\n",
    "        fn1 = fn.split('.')[0]\n",
    "\n",
    "        files_count += 1\n",
    "\n",
    "        #print('Loading MIDI file...')\n",
    "        score = TMIDIX.midi2ms_score(open(f, 'rb').read())\n",
    "\n",
    "        events_matrix = []\n",
    "\n",
    "        itrack = 1\n",
    "\n",
    "        patches = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "        patch_map = [[0, 1, 2, 3, 4, 5, 6, 7], # Piano \n",
    "                     [24, 25, 26, 27, 28, 29, 30], # Guitar\n",
    "                     [32, 33, 34, 35, 36, 37, 38, 39], # Bass\n",
    "                     [40, 41], # Violin\n",
    "                     [42, 43], # Cello\n",
    "                     [46], # Harp\n",
    "                     [56, 57, 58, 59, 60], # Trumpet\n",
    "                     [71, 72], # Clarinet\n",
    "                     [73, 74, 75], # Flute\n",
    "                     [-1], # Fake Drums\n",
    "                     [52, 53] # Choir\n",
    "                    ]\n",
    "\n",
    "        while itrack < len(score):\n",
    "            for event in score[itrack]:         \n",
    "                if event[0] == 'note' or event[0] == 'patch_change':\n",
    "                    events_matrix.append(event)\n",
    "            itrack += 1\n",
    "\n",
    "        events_matrix1 = []\n",
    "        for event in events_matrix:\n",
    "                if event[0] == 'patch_change':\n",
    "                    patches[event[2]] = event[3]\n",
    "\n",
    "                if event[0] == 'note':\n",
    "                    event.extend([patches[event[3]]])\n",
    "                    once = False\n",
    "                    \n",
    "                    for p in patch_map:\n",
    "                        if event[6] in p and event[3] != 9: # Except the drums\n",
    "                            event[3] = patch_map.index(p)\n",
    "                            once = True\n",
    "                            \n",
    "                    if not once and event[3] != 9: # Except the drums\n",
    "                        event[3] = 0 # All other instruments/patches channel\n",
    "                        event[5] = max(80, event[5])\n",
    "                        \n",
    "                    if event[3] < 11: # We won't write chans 11-16 for now...\n",
    "                        events_matrix1.append(event)\n",
    "                        stats[event[3]] += 1\n",
    "\n",
    "        # recalculating timings\n",
    "        \n",
    "        for e in events_matrix1:\n",
    "            e[1] = int(e[1] / 10)\n",
    "            e[2] = int(e[2] / 10)\n",
    "        \n",
    "        # final processing...\n",
    "        #=======================\n",
    "\n",
    "        if len(events_matrix1) > 0:\n",
    "            events_matrix1.sort(key=lambda x: (x[1], x[4]))\n",
    "\n",
    "            cho = []\n",
    "            pe = events_matrix1[0]\n",
    "            melody_chords = []\n",
    "            for e in events_matrix1:\n",
    "\n",
    "                time = min(31, e[1]-pe[1])\n",
    "                dur = max(1, min(127, e[2]))\n",
    "                cha = e[3]\n",
    "                ptc = min(127, e[4])\n",
    "                vel = min(127, e[5])\n",
    "\n",
    "                melody_chords.append([time, dur, ptc, cha, vel])\n",
    "\n",
    "                pe = e\n",
    "            melody_chords_f.append(melody_chords)\n",
    "\n",
    "        gfiles.append(f)\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print('Saving current progress and quitting...')\n",
    "        break  \n",
    "\n",
    "    except:\n",
    "        print('Bad MIDI:', f)\n",
    "        continue\n",
    "        \n",
    "print('=' * 70)\n",
    "        \n",
    "print('Done!')   \n",
    "print('=' * 70)\n",
    "\n",
    "print('Resulting Stats:')\n",
    "print('=' * 70)\n",
    "\n",
    "print('Piano:', stats[0])\n",
    "print('Guitar:', stats[1])\n",
    "print('Bass:', stats[2])\n",
    "print('Violin:', stats[3])\n",
    "print('Cello:', stats[4])\n",
    "print('Harp:', stats[5])\n",
    "print('Trumpet:', stats[6])\n",
    "print('Clarinet:', stats[7])\n",
    "print('Flute:', stats[8])\n",
    "print('Drums:', stats[9])\n",
    "print('Choir:', stats[10])\n",
    "\n",
    "print('=' * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "id": "0826f622-2edc-4f09-9a01-58df049738d4",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "# Process and mark INTs...\n",
    "\n",
    "INTS_f1 = []\n",
    "\n",
    "for chords_list in tqdm(melody_chords_f):\n",
    "    INTS_f1.append([-1, -1, -1, -1, -1]) # Intro\n",
    "    pe = chords_list[0]\n",
    "    count = 0\n",
    "    for i in chords_list:\n",
    "\n",
    "        INTS_f1.append(i)\n",
    "        \n",
    "        if count == len(chords_list)-50:\n",
    "            INTS_f1.append([-2, -2, -2, -2, -2]) # Outro\n",
    "        \n",
    "        count += 1\n",
    "        pe = i\n",
    "    INTS_f1.append([-3, -3, -3, -3, -3]) # End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INTS_f1[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "id": "3ee97039-6ebe-4896-846c-4564d7ee16cf",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "TMIDIX.Tegridy_Any_Pickle_File_Writer(INTS_f1, '/notebooks/Morpheus_INTS_32x128')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "id": "0553db32-585b-48bc-abd2-8b9aebde5c8f",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "INTS_f1 = TMIDIX.Tegridy_Any_Pickle_File_Reader('/notebooks/Morpheus_INTS_32x128')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "gradient": {
     "id": "53252e52-5e68-4e60-8e4d-a584667749a4",
     "kernelId": ""
    },
    "id": "lT0TyqUnpxu_"
   },
   "outputs": [],
   "source": [
    "#@title Load processed INTs datasets\n",
    "number_of_batches = 64 # Change this to your specs\n",
    "n_workers = 30 # Change this to your specs\n",
    "dataset_ratio = 0.25 # Change this if you want to limit input data\n",
    "val_dataset_ratio = 0.03 # Change this if you want to limit input data\n",
    "\n",
    "print('=' * 50)\n",
    "print('Prepping INTs datasets...')\n",
    "\n",
    "\n",
    "train_data1 = []\n",
    "\n",
    "avg_vel = int(sum([y[4] for y in INTS_f1]) / len(INTS_f1))\n",
    "\n",
    "pe = INTS_f1[0]\n",
    "\n",
    "for i in tqdm(INTS_f1):\n",
    "\n",
    "    if min(i) >= 0:\n",
    "        \n",
    "        if i[0] != 0:\n",
    "            train_data1.extend([i[0] + int(i[1] * 32)])\n",
    "\n",
    "        if i[4] > avg_vel: \n",
    "            train_data1.extend([(128 * 32) + 128 + (256 * i[3])+i[2]])\n",
    "        else:\n",
    "            train_data1.extend([(128 * 32) + (256 * i[3])+i[2]])\n",
    "\n",
    "        pe = i\n",
    "  \n",
    "    if i == [-1, -1, -1, -1, -1]: # Intro\n",
    "        train_data1.extend([(128 * 32)+(256 * 11)-3])\n",
    "\n",
    "    if i == [-2, -2, -2, -2, -2]: # Outro\n",
    "        train_data1.extend([(128 * 32)+(256 * 11)-2])\n",
    "\n",
    "    if i == [-3, -3, -3, -3, -3]: # End\n",
    "        train_data1.extend([(128 * 32)+(256 * 11)-1])\n",
    "\n",
    "train_data = train_data1[:int(len(train_data1) * dataset_ratio)]\n",
    "\n",
    "val_dataset = train_data[:int(len(train_data) * val_dataset_ratio)]\n",
    "test_dataset = train_data[:int(len(train_data) * val_dataset_ratio)]\n",
    "\n",
    "train_list = train_data\n",
    "val_list = val_dataset\n",
    "test_list = []\n",
    "print('=' * 50)\n",
    "\n",
    "print('Processing INTs datasets...')\n",
    "train_dataset = EPianoDataset(train_list, max_seq, random_seq)\n",
    "val_dataset = EPianoDataset(val_list, max_seq)\n",
    "test_dataset = EPianoDataset(test_list, max_seq)\n",
    "print('=' * 50)\n",
    "\n",
    "print('Loading INTs datasets...')\n",
    "batch_size = number_of_batches\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=n_workers, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=n_workers)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=n_workers)\n",
    "print('=' * 50)\n",
    "\n",
    "print('Total INTs in the dataset', len(train_data))\n",
    "print('Total unique INTs in the dataset', len(set(train_data)))\n",
    "print('Max INT in the dataset', max(train_data))\n",
    "print('Min INT in the dataset', min(train_data))\n",
    "print('=' * 50)\n",
    "\n",
    "print('Checking datasets shapes...')\n",
    "print('=' * 50)\n",
    "\n",
    "print('Train loader')\n",
    "for x, tgt in train_loader:\n",
    "    print(f'X shape: {x.shape}')\n",
    "    print(f'Target shape: {tgt.shape}')\n",
    "    break\n",
    "print('=' * 50)\n",
    "\n",
    "print('Validation loader')\n",
    "for x, tgt in val_loader:\n",
    "    print(f'X shape: {x.shape}')\n",
    "    print(f'Target shape: {tgt.shape}')\n",
    "    break\n",
    "print('=' * 50)\n",
    "\n",
    "print('Test loader')\n",
    "for x, tgt in test_loader:\n",
    "    print(f'X shape: {x.shape}')\n",
    "    print(f'Target shape: {tgt.shape}')\n",
    "    break\n",
    "print('=' * 50)\n",
    "\n",
    "print('Done! Enjoy! :)')\n",
    "print('=' * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the resulting INTs dataset..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "id": "708f16d3-1747-4e72-bcc9-7504cdd963d4",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "train_data[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "execution_count": 6,
     "id": "dd411e56-532f-47dd-8283-ecb57126a3ae",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "out = train_data[:16000]\n",
    "\n",
    "if len(out) != 0:\n",
    "    song = []\n",
    "    song = out\n",
    "    song_f = []\n",
    "    time = 0\n",
    "    dur = 0\n",
    "    vel = 0\n",
    "    pitch = 0\n",
    "    duration = 0\n",
    "    for s in song:\n",
    "        if s >= 0 and s < 128 * 32:\n",
    "            time += (s % 32) * 10\n",
    "            dur = (s // 32) * 10\n",
    "\n",
    "        if s >= 128 * 32 and s < (128 * 32) + (256 * 11):\n",
    "            if (s // 128) % 2 != 0:\n",
    "                vel = 90\n",
    "                channel = ((s-128-(128 * 32)) // 256)\n",
    "            else:\n",
    "                vel = 60\n",
    "                channel = ((s-(128 * 32)) // 256)\n",
    "\n",
    "            pitch = s % 256\n",
    "\n",
    "            song_f.append(['note', abs(time), dur, channel, pitch, vel ])\n",
    "\n",
    "    detailed_stats = TMIDIX.Tegridy_SONG_to_MIDI_Converter(song_f,\n",
    "                                                        output_signature = 'Morpheus',  \n",
    "                                                        output_file_name = '/notebooks/Morpheus-Music-Composition', \n",
    "                                                        track_name='Project Los Angeles', \n",
    "                                                        number_of_ticks_per_quarter=500)\n",
    "\n",
    "    print('Done!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fkVqviDzJOrv"
   },
   "source": [
    "# (TRAIN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y9CBW8xYupH8"
   },
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "gradient": {
     "id": "4aa21407-a3e9-4ed2-9bf1-83c295482b8a",
     "kernelId": ""
    },
    "id": "2moo7uUmpxvC"
   },
   "outputs": [],
   "source": [
    "#@title Train\n",
    "\n",
    "DIC_SIZE = max(train_data)+1\n",
    "\n",
    "config = GPTConfig(DIC_SIZE, \n",
    "                   max_seq,\n",
    "                   dim_feedforward=1024,\n",
    "                   n_layer=8, \n",
    "                   n_head=8, \n",
    "                   n_embd=1024,\n",
    "                   enable_rpr=True,\n",
    "                   er_len=max_seq)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = GPT(config)\n",
    "\n",
    "model = nn.DataParallel(model)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "#=====\n",
    "\n",
    "init_step = 0\n",
    "lr = LR_DEFAULT_START\n",
    "lr_stepper = LrStepTracker(d_model, SCHEDULER_WARMUP_STEPS, init_step)\n",
    "eval_loss_func = nn.CrossEntropyLoss(ignore_index=DIC_SIZE)\n",
    "train_loss_func = eval_loss_func\n",
    "\n",
    "opt = Adam(model.parameters(), lr=lr, betas=(ADAM_BETA_1, ADAM_BETA_2), eps=ADAM_EPSILON)\n",
    "lr_scheduler = LambdaLR(opt, lr_stepper.step)\n",
    "\n",
    "\n",
    "#===\n",
    "\n",
    "best_eval_acc        = 0.0\n",
    "best_eval_acc_epoch  = -1\n",
    "best_eval_loss       = float(\"inf\")\n",
    "best_eval_loss_epoch = -1\n",
    "best_acc_file = '/notebooks/gpt2_rpr_acc.pth'\n",
    "best_loss_file = '/notebooks/gpt2_rpr_loss.pth'\n",
    "loss_train, loss_val, acc_val = [], [], []\n",
    "\n",
    "for epoch in range(0, epochs):\n",
    "    new_best = False\n",
    "    \n",
    "    loss = train(epoch+1, \n",
    "                 model, train_loader, \n",
    "                 train_loss_func, \n",
    "                 opt, \n",
    "                 lr_scheduler, \n",
    "                 num_iters=-1, \n",
    "                 save_checkpoint_steps=4000)\n",
    "    \n",
    "    loss_train.append(loss)\n",
    "    \n",
    "    eval_loss, eval_acc = eval_model(model, val_loader, eval_loss_func, num_iters=-1)\n",
    "    loss_val.append(eval_loss)\n",
    "    acc_val.append(eval_acc)\n",
    "    \n",
    "    if(eval_acc > best_eval_acc):\n",
    "        best_eval_acc = eval_acc\n",
    "        best_eval_acc_epoch  = epoch+1\n",
    "        torch.save(model.state_dict(), best_acc_file)\n",
    "        new_best = True\n",
    "\n",
    "    if(eval_loss < best_eval_loss):\n",
    "        best_eval_loss       = eval_loss\n",
    "        best_eval_loss_epoch = epoch+1\n",
    "        torch.save(model.state_dict(), best_loss_file)\n",
    "        new_best = True\n",
    "    \n",
    "    if(new_best):\n",
    "        print(\"Best eval acc epoch:\", best_eval_acc_epoch)\n",
    "        print(\"Best eval acc:\", best_eval_acc)\n",
    "        print(\"\")\n",
    "        print(\"Best eval loss epoch:\", best_eval_loss_epoch)\n",
    "        print(\"Best eval loss:\", best_eval_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "id": "72338f3f-34c4-40e3-a48a-42ed9729466a",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "# Eval funct to eval separately if needed\n",
    "\n",
    "#=====\n",
    "\n",
    "init_step = 0\n",
    "lr = LR_DEFAULT_START\n",
    "lr_stepper = LrStepTracker(d_model, SCHEDULER_WARMUP_STEPS, init_step)\n",
    "eval_loss_func = nn.CrossEntropyLoss(ignore_index=DIC_SIZE)\n",
    "train_loss_func = eval_loss_func\n",
    "\n",
    "opt = Adam(model.parameters(), lr=lr, betas=(ADAM_BETA_1, ADAM_BETA_2), eps=ADAM_EPSILON)\n",
    "lr_scheduler = LambdaLR(opt, lr_stepper.step)\n",
    "\n",
    "\n",
    "eval_loss, eval_acc = eval_model(model, val_loader, eval_loss_func, num_iters=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "gradient": {
     "id": "0e338550-f170-44a6-9479-ba0ddbc64608",
     "kernelId": ""
    },
    "id": "NNqmcFdRyC2M"
   },
   "outputs": [],
   "source": [
    "#@title Plot resulting training loss graph\n",
    "\n",
    "tr_loss_list = [item for sublist in loss_train for item in sublist]\n",
    "plt.plot([i for i in range(len(tr_loss_list))] ,tr_loss_list, 'b')\n",
    "plt.savefig('/notebooks/Morpheus-Training-Loss-Graph.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mdKFoeke9L7H"
   },
   "source": [
    "# (SAVE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "gradient": {
     "id": "73bea62d-084b-4f9a-9e55-2b34a932a7a4",
     "kernelId": ""
    },
    "id": "gqyDatHC9X1z"
   },
   "outputs": [],
   "source": [
    "#@title Save the model\n",
    "\n",
    "print('Saving the model...')\n",
    "full_path_to_model_checkpoint = \"/notebooks/Morpheus-Trained-Model.pth\" #@param {type:\"string\"}\n",
    "torch.save(model.state_dict(), full_path_to_model_checkpoint)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YzCMd94Tu_gz"
   },
   "source": [
    "# Congrats! You did it! :)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Optimus_VIRTUOSO_Multi_Instrumental_RGA_Edition.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
